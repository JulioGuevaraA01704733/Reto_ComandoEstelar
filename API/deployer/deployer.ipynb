{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "48c2fd1b",
      "metadata": {
        "id": "48c2fd1b"
      },
      "source": [
        "## Deployer de lil API"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ece8635",
      "metadata": {
        "id": "4ece8635"
      },
      "source": [
        "Creación de workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff4fa292",
      "metadata": {
        "id": "ff4fa292"
      },
      "source": [
        "Procura cambiar el nombre del grupo de recursos cada que lo corras para inicializar en otro y que sea más fácil\n",
        "\n",
        "Si vas a llamar un grupo de recursos ya existente, cambias create por get\n",
        "Puedes comentar la locación si solo vas a llamar a uno ya existente\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e25f7c",
      "metadata": {
        "id": "b1e25f7c",
        "outputId": "91199580-c4a8-4330-d2ee-c01422f3befd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning up past default Resource Group Deployments on the subscription to avoid limit of 10\n",
            "Deleting past Resource Group Deployment with name: DeployResourceGroup-0841292edf\n",
            "Deploying KeyVault with name servicekeyvaultd4aceadb9.\n",
            "Deploying StorageAccount with name servicestorageb55585093c.\n",
            "Deploying AppInsights with name serviceinsightsfdf5c3309.\n",
            "Deployed AppInsights with name serviceinsightsfdf5c3309. Took 30.5 seconds.\n",
            "Deploying Workspace with name service.\n",
            "Deployed Workspace with name service. Took 40.4 seconds.\n",
            "Registering model model_predictionnnnnn\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from azureml.core.model import Model\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "# Cargando el archivo con el ID\n",
        "id = open('id_conf.json', 'r')\n",
        "mi = json.load(id)\n",
        "\n",
        "# El tenant ID está en AZURE BUSCANDO MICROSOFT ENTRA ID\n",
        "tenant_id = mi[\"tenant_id\"]\n",
        "\n",
        "# Autenticación interactiva\n",
        "interactive_auth = InteractiveLoginAuthentication(tenant_id=tenant_id)\n",
        "\n",
        "# Autenticación con el ID del archivo\n",
        "my_id = mi[\"id\"]\n",
        "\n",
        "# Creando el workspace llamando el ID\n",
        "ws = Workspace.create(name=\"service\",\n",
        "                      subscription_id = my_id,\n",
        "                      resource_group = \"tca_grupo_recursos\",\n",
        "                      location = \"centralindia\"\n",
        "                      )\n",
        "\n",
        "# Registrando el modelo\n",
        "model_name = \"model_predictionnnnnn\"\n",
        "registered_model = Model.register(model_path=\"svm_model.pkl\",\n",
        "                                  model_name=model_name,\n",
        "                                  workspace=ws)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ac73572",
      "metadata": {
        "id": "0ac73572"
      },
      "source": [
        "El workspace que creas necesitará tener permisos de AZURE CONTAINER INSTANCES.\n",
        "Para esto:\n",
        "1) Entras al Grupo de Recursos en Azure recién creado y vas a la izquierda en Access control (IAM).\n",
        "2) Abajo encuentras la caja que dice 'Grant access to this resource' y presionas _Add role assignment_.\n",
        "3) Role: busca _Azure Container Instances_. Next; Members: _+ Select members_ y pegas el output del siguiente código y picas _Select_.\n",
        "\n",
        "```\n",
        "ws.get_details()['identity']['principal_id']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3d017f",
      "metadata": {
        "id": "df3d017f"
      },
      "source": [
        "pica _review + assign_ y vuelve a llamar al Workspace actualizado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creando el workspace llamando el ID\n",
        "ws = Workspace.get(name=\"workspace_ce\",\n",
        "                   subscription_id = my_id,\n",
        "                   resource_group = \"tca_grupo_recursos\"\n",
        "                   )"
      ],
      "metadata": {
        "id": "japltfH7tKlF"
      },
      "id": "japltfH7tKlF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "64b1f87d",
      "metadata": {
        "id": "64b1f87d"
      },
      "source": [
        "A continuación el código _score.py_. Ten en cuenta que para implementaciones en la nube ya no se puede llamar el dataset de manera local, sino que nesecitas que Azure lo haga. Según chatGPT el código es así:\n",
        "\n",
        "- model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"svm_model.pkl\")\n",
        "- model = joblib.load(model_path)\n",
        "\n",
        "Nota: no olvides definir global model.\n",
        "\n",
        "Los print que están en el código son para debuggear, especialmente para la implementación local en Docker."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5441a263",
      "metadata": {
        "id": "5441a263"
      },
      "outputs": [],
      "source": [
        "################ score.py ###################\n",
        "\n",
        "scorepy = \"\"\"\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from azureml.core.model import Model\n",
        "\n",
        "def init():\n",
        "  global model\n",
        "  try:\n",
        "    model_path = Model.get_model_path(\"svm_model1\")\n",
        "    model = joblib.load(model_path)\n",
        "  except Exception as e:\n",
        "    raise\n",
        "\n",
        "\n",
        "def run(raw_data):\n",
        "  try:\n",
        "    # raw_data viene como JSON preprocesado desde la API\n",
        "    if isinstance(raw_data, str):\n",
        "      data_dict = json.loads(raw_data)\n",
        "    else:\n",
        "      data_dict = [raw_data]\n",
        "\n",
        "    # Convertir directamente a DataFrame\n",
        "    data = pd.DataFrame(data_dict)\n",
        "\n",
        "    # Predecir directamente (el modelo ya tiene scaler dentro)\n",
        "    result = model.predict(data)\n",
        "\n",
        "    if isinstance(raw_data, str):\n",
        "      return json.dumps(result)\n",
        "    else:\n",
        "      return json.dumps(int(result[0]))\n",
        "\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    return json.dumps(str(e))\n",
        "\"\"\"\n",
        "\n",
        "file_score = open(\"score.py\", \"w\")\n",
        "file_score.write(scorepy)\n",
        "file_score.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3adff59f",
      "metadata": {
        "id": "3adff59f"
      },
      "source": [
        "En esta parte es importante recalcar que es donde se agregan las dependencias, por lo que también se podría agregar con un .txt o con un .yml. Por ejemplo:\n",
        "- v_env = Environment.from_conda_specification(name=\"comando_estelar_env1\", file_path=\"environment.yml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a38d88",
      "metadata": {
        "id": "e0a38d88",
        "outputId": "7599fc60-69b6-48d6-bba2-2243dfc2c0bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_26716\\2981551881.py:18: FutureWarning: azureml.core.model:\n",
            "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
            "please refer to respective documentations \n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
            "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
            "For more information on migration, see https://aka.ms/acimoemigration \n",
            "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
            "  service = Model.deploy(workspace=ws,\n"
          ]
        }
      ],
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "# Configurando el entorno de virtual\n",
        "v_env = Environment(\"comando_estelar_env1\")\n",
        "v_env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'scikit-learn', 'numpy'])\n",
        "\n",
        "# Configurando el entorno de inferencia\n",
        "inference_config = InferenceConfig(\n",
        "                                environment=v_env,\n",
        "                                entry_script=\"score.py\",\n",
        "                                )\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1.5, memory_gb=3)\n",
        "\n",
        "# Construyendo el servicio\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name='service1',\n",
        "                       models=[registered_model],\n",
        "                       inference_config=inference_config,\n",
        "                       deployment_config=aci_config,\n",
        "                       overwrite=True, # Sobrescribir si ya existe\n",
        "                       )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4bc9170",
      "metadata": {
        "id": "b4bc9170"
      },
      "source": [
        "Ya que está eso falta ver el deployment del servicio. Como se tarda tanto en correr está el código configurado para que enseñe todos los outputs y podamos ver qué tanto ha avanzado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b803d986",
      "metadata": {
        "id": "b803d986",
        "outputId": "a85ab056-ce59-427d-e38a-497fa3796905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2025-06-06 00:25:51-06:00 Creating Container Registry if not exists..\n",
            "2025-06-06 00:35:51-06:00 Registering the environment.\n",
            "2025-06-06 00:35:53-06:00 Building image."
          ]
        }
      ],
      "source": [
        "# Esperando a que el servicio se despliegue\n",
        "service.wait_for_deployment(show_output=True)\n",
        "\n",
        "# Guardando la URI del servicio\n",
        "scoring_uri = service.scoring_uri\n",
        "key = service.get_keys()[0]  # Obteniendo la clave de acceso\n",
        "\n",
        "# Guardando la URI en un archivo JSON\n",
        "scoreuri = json.dumps({\"URI\": [scoring_uri], \"Key\": key})\n",
        "file = open(\"uri.json\", \"w\")\n",
        "file.write(scoreuri)\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4fececc3",
      "metadata": {
        "id": "4fececc3"
      },
      "source": [
        "Adicional: Para correr esto en Docker de manera local y observar si el código funciona correctamente hacemos lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55a6a527",
      "metadata": {
        "id": "55a6a527"
      },
      "outputs": [],
      "source": [
        "from azureml.core.webservice import LocalWebservice\n",
        "local_config = LocalWebservice.deploy_configuration()\n",
        "service = Model.deploy(ws, \"local-svc\", [registered_model], inference_config, local_config)\n",
        "service.wait_for_deployment(show_output=True)\n",
        "# Imprimiendo la URI del servicio\n",
        "print(\"Local service URI:\", service.scoring_uri)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
